<h3>Under the Hood: Training a Digit Classifier</h3>

<h4>chap_4_mnist_baseline.ipynb</h4>
In this chapter, 1st half is dedicated to understand the basics of how a computer internally tries to classify a image of a handwritten digits. So we are trying to create a baseline model to train a digit classifier. After creating a model we will try to validate that using the handwritten images from the validation set. 

<h4>chap_4_sgd_basics.ipynb</h4>
In this notebook we will explore the basics of Stochastic Gradient Descent (SGD), and also learn about the importance of each step in the process.

<h4>chap_4_sgd_example.ipynb</h4>
In this notebook we will apply the SGD to finding out the speed of the Roller Coaster and learn how can we minimize the loss and im prove accuracy.

<h4>chap_4_sgd_mnist.ipynb</h4>
In this notebook we will apply the SGD to our actual problem we started with, i.e MNIST Hand Written Digits.

The detailed explanation of the above is written in the following blogpost's titled 
1. "Deep Learning for Coders / Chapter-4 / Week-4 (Part-1)": <a href="https://ravichandraveeramachaneni.github.io/posts/bp5/">Deep Learning for Coders / Chapter-4 / Week-4 (Part-1)</a>
2. "Deep Learning for Coders / Chapter-4 / Week-4 (Part-2)": <a href="https://ravichandraveeramachaneni.github.io/posts/bp6/">Deep Learning for Coders / Chapter-4 / Week-4 (Part-2)</a>

